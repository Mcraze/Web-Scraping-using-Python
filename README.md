# Wikipedia Web Scraping using Python

### Problem Statement:
As part of this project, the task is to perform web scraping on the Wikipedia page titled "List of largest companies in the United States by revenue." The goal is to extract the tabular data from the webpage, which contains a comprehensive list of the largest companies in the United States ranked by revenue.
<br>
Using Python and web scraping libraries, the project aims to fetch the table from the Wikipedia page and convert it into a structured format, such as a pandas DataFrame. Once the data is extracted and structured appropriately, the objective is to save it as a CSV file for further analysis and use.

### Data to be Scraped:
![image](https://github.com/Mcraze/Web-Scraping-using-Python/assets/84672998/52c4eb9e-aede-41c4-b7f4-20b0313e5625)

### Python Libraries used:
- BeautifulSoup
- Requests
- Python Pandas

### Steps taken to Scrap the data:
- Importing necessary libraries
- Sending request to wikipedia page
- Using BeautifulSoup to extract relevant data from html
- Locating the table to be used as dataframe
- Data cleaning and transformation
- Exporting the data as CSV file

### Cleaned Data:
![image](https://github.com/Mcraze/Web-Scraping-using-Python/assets/84672998/778c5f21-2101-4b7f-be17-49aacc65a464)

### Final Conclusion:
The project successfully accomplished web scraping of data from the Wikipedia page titled "List of largest companies in the United States by revenue." Utilizing Python web scraping libraries, the relevant table containing the list of largest US companies and their revenue data was extracted.
<br>
Following data cleaning and transformation, a structured pandas DataFrame was created, and the dataset was saved as a CSV file named "Final Data.csv." The resulting CSV file now provides a valuable resource for analyzing and understanding the largest companies in the US based on their revenue.
